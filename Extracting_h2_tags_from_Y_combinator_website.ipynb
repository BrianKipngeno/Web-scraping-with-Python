{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOT1ncoO2zOHBVWj1OtUBDy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrianKipngeno/Web-scrapping-with-Python/blob/main/Extracting_h2_tags_from_Y_combinator_website.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Obtaining the data**\n",
        "\n",
        "We first need to retrieve the HTML content from the Y Combinator \"About\" page using the requests library. The URL is provided, and we use requests.get() to get the HTML content."
      ],
      "metadata": {
        "id": "rMAltuj4VYaa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4jHIacs6VLPA"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "# Define the URL of the Y Combinator About page\n",
        "url = 'https://www.ycombinator.com/about/'\n",
        "\n",
        "# Make a GET request to fetch the HTML content of the page\n",
        "response = requests.get(url)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Parsing**\n",
        "\n",
        "Once the HTML content is obtained, we use BeautifulSoup to parse it, making the page structure easier to navigate and extract information from."
      ],
      "metadata": {
        "id": "rSFDcfLLWyGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Parse the HTML content using BeautifulSoup\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n"
      ],
      "metadata": {
        "id": "Axlehg0MW909"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Extracting required elements**\n",
        "\n",
        "We use the find_all() method of BeautifulSoup to extract all the h2 tags from the parsed HTML structure. Each h2 tag is then looped through to print or process the content."
      ],
      "metadata": {
        "id": "kW5B3MwbXx4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find all h2 tags\n",
        "h2_tags = soup.find_all('h2')\n",
        "\n",
        "# Extract and print the text from each h2 tag\n",
        "for index, h2 in enumerate(h2_tags, start=1):\n",
        "    print(f\"H2 Tag {index}: {h2.text.strip()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxQaAirsX1S4",
        "outputId": "baa3d177-9df6-4bd5-b70e-4f57bf2113fe"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "H2 Tag 1: Footer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Saving our data**\n",
        "\n",
        "Finally, we could save this extracted data. For example, we can store the content in a list or save it to a file. Below is a modified version that saves the extracted h2 text to a list:"
      ],
      "metadata": {
        "id": "IVPUkHLvYH8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Store h2 tags content in a list\n",
        "h2_texts = [h2.text.strip() for h2 in h2_tags]\n",
        "\n",
        "# Print or save h2_texts as required\n",
        "# For example, save to a file:\n",
        "with open('h2_content.txt', 'w') as file:\n",
        "    for h2_text in h2_texts:\n",
        "        file.write(f\"{h2_text}\\n\")"
      ],
      "metadata": {
        "id": "4BO6yMYkYHCn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preview the saved data\n",
        "print(\"\\nPreview of saved H2 content:\\n\")\n",
        "with open('h2_content.txt', 'r') as file:\n",
        "    for line in file.readlines():\n",
        "        print(line.strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fT-oHjnYsSi",
        "outputId": "8033141f-7dd5-4de0-cb11-f761e1429fe9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Preview of saved H2 content:\n",
            "\n",
            "Footer\n"
          ]
        }
      ]
    }
  ]
}